---
permalink: /
title: "Bio"
excerpt: "Bio"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am interested in the intersection of machine learning and scientific computing for simulating physical systems. I graduated from the University of California, Berkeley with highest honors in Applied Mathematics in 2012. I then graduated from the Institute of Computational and Mathematical Engineering (ICME) at Stanford University with my Masters of Science in 2015 and with my PhD in Computational and Mathematical Engineering in 2018. In my PhD research, I developed novel finite volume averaged-based methods for nonlinear porous media flow. I was advised by Professor Margot Gerritsen. After graduating in 2018, I joined AWS AI Labs at Amazon Web Services as an Applied Scientist, where I worked on developing and researching deep learning models for probabilistic time series forecasting. In 2021, I was promoted to Senior Applied Scientist and have been working on the DeepEarth team, researching physics-constrained machine learning models.


## News
- We are organizing a [Deep Learning for Summer School](https://sites.google.com/lbl.gov/dl4sci2026/home?authuser=0) at the Lawrence Berkeley Lab (LBL) on July 20-24, 2026!
- Our 3 papers on [compressing](https://arxiv.org/pdf/2510.03358?) and [designing](https://arxiv.org/pdf/2510.19236) time series foundation models and enforcing [differentiable hard constraints with UQ](https://arxiv.org/pdf/2506.07003) with applications to SciML and hierarchical forecasting were accepted at ICLR 2026!
- Two of my research works made the list for [Amazon Science's Top 5 for 2025](https://thekernel.news/articles/amazon-science-top-5-2025/) and the [Top 10 Amazon Science blogs for 2025](https://www.amazon.science/blog/the-10-most-viewed-blog-posts-of-2025): our tabular foundation model Mitra and SciML works on Science in the Age of Foundation Models.
- My perspective piece on [Science in the Age of Foundation Models](https://www.amazon.science/blog/science-in-the-age-of-foundation-models) discusses the potential and current limitations of foundation models for science with applications to weather forecasting and aerodynamics.
- We have added support for [Multi-LoRA with GPT-OSS](https://github.com/vllm-project/vllm/pull/21229) in vLLM.
- Our tabular foundation model (TFM) [Mitra](https://arxiv.org/abs/2510.21204), which is trained purely on synthetic data is accepted at NeurIPS 2025 and is available on [Hugging Face](https://huggingface.co/autogluon/mitra-classifier) and [AutoGluon 1.4](https://auto.gluon.ai/dev/tutorials/tabular/tabular-foundational-models.html)!
- See my talk on time series foundation model [Chronos](https://arxiv.org/pdf/2403.07815) at the Lawrence Berkeley Lab (LBL) deep learning summer school [here](https://www.youtube.com/watch?v=4R4as2XABWg)!
- We are hosting a [ICLR 2024 Workshop on AI4DifferentialEquations In Science](https://iclr.cc/virtual/2024/workshop/20581)!
- I gave an invited talk on ["Physics-constrained Machine Learning for Earth and Sustainability Science"](https://www.youtube.com/watch?v=qflj9ZPL1vo) at the [2nd AI for Good Webinar Series for AI for Earth and Sustainability Science](https://aiforgood.itu.int/event/physics-constrained-machine-learning-for-scientific-computing/).
- I gave an invited talk on ["Physics-constrained Machine Learning for Scientific Computing"](https://www.youtube.com/watch?v=ag5qEEYTNFg) at the [Machine Learning and Dynamical Systems Seminar](https://www.turing.ac.uk/research/interest-groups/machine-learning-and-dynamical-systems) at the Alan Turing Institute with the highest number of views and a corresponding amazon science [blog](https://www.amazon.science/blog/physics-constrained-machine-learning-for-scientific-computing).
- Our two papers on **physics-constrained machine learning** were accepted at ICML 2023 and ICLR 2023 on satisfying [conservation laws](https://www.amazon.science/publications/learning-physical-models-that-can-respect-conservation-laws) and [boundary conditions](https://www.amazon.science/publications/guiding-continuous-operator-learning-through-physics-based-boundary-constraints), respectively.
- Our paper on the theoretical guarantees of ensembling for time series forecasting was accepted at ICML 2023.
- Our papers on [domain adaptation](https://proceedings.mlr.press/v162/jin22d/jin22d.pdf) and [eliminating quantile crossing](https://proceedings.mlr.press/v151/park22a/park22a.pdf) for time series forecasting were accepted at ICML 2022 and AISTATS 2022, respectively.
- Our paper on [forecasting the spread of COVID-19](http://proceedings.mlr.press/v144/wang21a/wang21a.pdf) won the [**Best Paper Award**](https://www.amazon.science/blog/paper-on-forecasting-spread-of-covid-19-wins-best-paper-award) at the Machine Learning and Public Health NeurIPS workshop in 2020 and was accepted at L4DC 2021.
